<!DOCTYPE HTML>
<html>
    <head>
        <title>Hybrid Residual Reinforcement Learning on a Multi-Modal Legged Robot</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="flickity.css">
        <link rel="stylesheet" href="style.css" />
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-89797207-1', 'auto');
          ga('send', 'pageview');
        </script>
        <script src="flickity.pkgd.js"></script>
    </head>
    <body id="body">
        <div id="main"> 
            <header id="header">
            </header>
            <!-- style="padding-bottom:1em" -->
            <div id="profile">
                <!-- <img src="images/profile.jpg"> -->
                <div id="profile-desc">
                    <div id="profile-name">Hybrid Residual Reinforcement Learning on a Multi-Modal Legged Robot
                        <p><br>Under review as a conference paper at ICRA 2022</p>
                    </div>
                    <p>
                        <b>Abstract</b>. While quadruped robots usually have good stability and load capacity, bipedal robots offer a higher level of flexibility / adaptability to different tasks and environments. A multi-modal legged robot can take the best of both worlds. In this paper, we show a complete pipeline of design, control, and sim-to-real transfer of a multi-modal legged robot. We 1) design an additional supporting structure for a quadruped robot, 2) evaluate a class of novel hybrid learning-based algorithms combining different reinforcement learning algorithms (Twin Delayed Deep Deterministic Policy Gradients and Soft Actor Critic) and black-box parameter optimisers (Evolutionary Strategy and Bayesian Optimisation), and 3) propose a sim-to-real transfer technique. We use parameter optimisers to tune a conventional feedback controller simultaneously with the training of an RL agent that solves the residual task. Experimental results show that our proposed algorithms have the best performance in simulation and competitive performance on the real robot with our sim-to-real technique. Overall, our multi-modal robot could successfully switch between biped and quadruped, and walk in both modes.  
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>
            <div class="section paper">
                <!-- <h1>Highlights</h1> -->
                <p align="center">
                <iframe width="820" height="461.25" src="https://www.youtube.com/embed/Xf-fKWNRLcc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </p>
            </div>
            <br>
            <!-- <div class="divider"></div> -->

            <div class="divider"></div>  
            <div class="section paper">
                <h1>Simulation Results</h1>
                <p>Overall, standard TD3 can outperform SAC and all the parametric controllers with parameter optimisers, while our proposed hybrid methods with TD3 can even surpass the standard TD3. </p>
                
                
                    <div class="main-carousel" data-flickity='{ "cellAlign": "left", "contain": true, "wrapAround": true, "autoPlay": 3000, "groupCells": true, "groupCells": 1, "prevNextButtons": true, "pageDots": false, "resize": false}'>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/Sine_big.png" alt="grapes" width="600" height="600"/>
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/Rose_big.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/Triangle_big.png" alt="grapes" width="600" height="600" />
                    </div>
                    <div class="carousel-cell">
                        <img class="carousel-cell-image"
                        src="images/Line_big.png" alt="grapes" width="600" height="600" />
                    </div>
                </div>
                
                <!-- <a><img src="images/Line_big.png"></a>
                <a><img src="images/Sine_big.png"></a>
                <a><img src="images/Rose_big.png"></a>
                <a><img src="images/Triangle_big.png"></a> -->
            </div>

            <br>
            <br>
            <div class="divider"></div>

            <!-- <div class="section paper">
                <h1>Experimental Results</h1>
                <p>Latest version (Oct 28, 2020): <a href="https://arxiv.org/abs/2010.14406">arXiv:2010.14406 [cs.RO]</a>.<br>Published at the Conference on Robot Learning (CoRL) 2020<br>
                    <font color="4e79a7">&#9733; Plenary Talk, Best Paper Presentation Award Finalist, CoRL &#9733;</font></p><br>
                <a href="https://arxiv.org/pdf/2010.14406.pdf"><img src="images/thumbnail-half.jpg"></a>
            </div>
            <div class="divider"></div> -->

            <div class="section paper">
                <h1>Paper</h1>
                <p>Under review as a conference paper at ICRA 2022<br></p>
                    <!-- <font color="4e79a7">&#9733; Plenary Talk, Best Paper Presentation Award Finalist, CoRL &#9733;</font></p><br> -->
                <a href="files/finalfinal.pdf"><img src="images/thumbnail-half.jpg"></a>
            </div>
            <div class="divider"></div>


            <div class="section paper half">
                <h1>Code</h1>
                <p>
                    Code is available on Github. Includes:<br>
                    <!-- &nbsp;&nbsp;&bull;&nbsp;&nbsp;3D models (STL files for 3D printing and OBJ files for simulation).<br> -->
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a href="https://github.com/Chenaah/Cheetah-Gym">Simulation environments</a> (with PyBullet).<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a href="https://github.com/Chenaah/Cheetah-Trainer">Training/testing code</a> (with TensorFlow/Python).<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;<a href="https://github.com/Chenaah/Cheetah-Software-RL">Program on the real robot</a> (with TensorFlow/C++).<br><br>
                    <br>
                </p>

            </div>
            <div class="section bibtex half">
                <h1>Bibtex</h1>
                <div class="code">@article{yu2021hybrid,<br>
                &nbsp;&nbsp;&nbsp;&nbsp;title={Hybrid Residual Reinforcement Learning on a Multi-Modal Legged Robot},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;author={Chen Yu and Andre Rosendo},<br>
                <!-- &nbsp;&nbsp;&nbsp;&nbsp;journal={XXX},<br> -->
                &nbsp;&nbsp;&nbsp;&nbsp;year={2021}<br>
                }</div>
            </div>    
            <div class="divider"></div>
            <!-- <div class="section team">
                <h1>Team</h1>
                <div class="people-profile">
                    <a href="https://andyzeng.github.io/"><img src="images/people/andy.jpg"><p>Andy Zeng</p></a>
                </div>
                <div class="people-profile">
                    <a href="http://www.peteflorence.com/"><img src="images/people/pete.jpg"><p>Pete Florence</p></a>
                </div>
                <div style="clear: both;"></div>
            </div> -->
            <!-- <div class="section teamlogo">
                <img src="images/logo.png">
                <p>Robotics at Google</p>
            </div>
            <div style="clear: both;"></div> -->
            <div class="divider"></div>
            
            <!-- <div class="section highlights">
                <h1>Highlights</h1>
                <a href="https://ai.googleblog.com/2021/02/rearranging-visual-world.html"><img style="height: 80px; margin-left: 30px; margin-bottom: 10px" src="images/aiblog.png"></a>
                <a href="https://venturebeat.com/2020/10/28/googles-transporter-networks-learn-to-stack-blocks-and-assemble-mouthwash-kits-from-as-few-examples/"><img style="height: 26px; margin-top: 31px; margin-left: 30px; margin-bottom: 10px" src="images/vb.png"></a>
            </div>
            <div style="clear: both;"></div>
            <div class="divider"></div>
            
            <div class="section video">
                <h1>Plenary Talk</h1>
                <p>Watch it on YouTube (<a href="https://youtu.be/8afHfReCfPo?t=12214">link</a>)<br><a href="https://youtu.be/8afHfReCfPo?t=12214"><img src="images/talk-thumbnail.png" width="640px" style="border: 2px solid #191e3f; margin-top: 10px"></a></p>
            </div>
            <div class="section video">
                <h1>Supplemental Video</h1>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/496UVuAdOP4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
            <div class="section video">
                <h1>Method</h1>
                <video style="margin-left: 30px; width: 480px; margin-bottom: 30px" playsinline="" muted="" autoplay="" loop="">
                    <source src="images/animation.mp4" type="video/mp4">
                </video>
            </div>
            <div class="divider"></div> -->
            
            <div class="section acknowledgements">
                <h1>Acknowledgements</h1>
                <p>Special thanks to Jinyue Cao, Heng Zhang, Zhongwei Luo for mathematical advice; Xiaozhu Lin, Wenqing Jiang for hardware support; Zhikang Liu, Jun Gu for video shooting. </p><br><br>
                    <!-- helpful feedback on writing; Sean Snyder, Jonathan Vela, Larry Bisares, Michael Villanueva, Brandon Hurd for operations and hardware support; Robert Baruch for software infrastructure, Jared Braun for UI contributions; Erwin Coumans for PyBullet advice; Laura Graesser for video narration. -->
            </div>
            <br><br><br><br><br><br><br><br><br><br>
            <div class="divider"></div>
        </div>
    </body>
</html>